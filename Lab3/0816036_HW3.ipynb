{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3: Decision Tree, AdaBoost and Random Forest\n",
    "In hw3, you need to implement decision tree, adaboost and random forest by using only numpy, then train your implemented model by the provided dataset. TA will use the on-hold test label to evaluate your model performance.\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling `sklearn.tree.DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 5 of hw3 slides](https://docs.google.com/presentation/d/1kIe_-YZdemRMmr_3xDy-l0OS2EcLgDH7Uan14tlU5KE/edit#slide=id.gd542a5ff75_0_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def gini(sequence):\n",
    "    sequence = sequence.astype(dtype='int64')\n",
    "    counts = np.bincount(sequence)\n",
    "    probs = counts / sequence.size\n",
    "    gini = 1\n",
    "    for p in probs:\n",
    "        if p > 0:\n",
    "            gini -= p * p\n",
    "    return gini\n",
    "\n",
    "def compute_gini_gain(parent, left, right):\n",
    "    ratio_left = len(left) / len(parent)\n",
    "    ratio_right = 1 - ratio_left\n",
    "    return gini(parent) - ratio_left * gini(left) - ratio_right * gini(right)\n",
    "\n",
    "def entropy(sequence):\n",
    "    sequence = sequence.astype(dtype='int64')\n",
    "    counts = np.bincount(sequence)\n",
    "    probs = counts / sequence.size\n",
    "    entropy = 0\n",
    "    for p in probs:\n",
    "        if p > 0:\n",
    "            entropy -= p * np.log2(p)\n",
    "    return entropy\n",
    "\n",
    "def compute_info_gain(parent, left, right):\n",
    "    ratio_left = len(left) / len(parent)\n",
    "    ratio_right = 1 - ratio_left\n",
    "    return entropy(parent) - ratio_left * entropy(left) - ratio_right * entropy(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini of data is  0.4628099173553719\n"
     ]
    }
   ],
   "source": [
    "print(\"Gini of data is \", gini(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of data is  0.9456603046006401\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy of data is \", entropy(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "It is a binary classifiation dataset that classify if price is high or not for a cell phone, the label is stored in `price_range` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 21)\n",
      "(300, 21)\n",
      "(1500, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "val_df = pd.read_csv('val.csv')\n",
    "x_test_df = pd.read_csv('x_test.csv')\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "trainval_df  = pd.concat([train_df, val_df])\n",
    "print(trainval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[[1 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "x_train_data = train_df.drop(\"price_range\", axis=1)\n",
    "y_train_data = train_df[\"price_range\"]\n",
    "\n",
    "x_val_data = val_df.drop(\"price_range\", axis=1).to_numpy()\n",
    "y_val_data = val_df[\"price_range\"].to_numpy(dtype='int64')\n",
    "\n",
    "x_test_data = x_test_df.to_numpy()\n",
    "\n",
    "print(type(x_train_data))\n",
    "print(np.array(y_train_data).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'battery_power', 1: 'blue', 2: 'clock_speed', 3: 'dual_sim', 4: 'fc', 5: 'four_g', 6: 'int_memory', 7: 'm_dep', 8: 'mobile_wt', 9: 'n_cores', 10: 'pc', 11: 'px_height', 12: 'px_width', 13: 'ram', 14: 'sc_h', 15: 'sc_w', 16: 'talk_time', 17: 'three_g', 18: 'touch_screen', 19: 'wifi'}\n"
     ]
    }
   ],
   "source": [
    "category = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']\n",
    "headers = x_train_data.columns.tolist()\n",
    "column_names = {}\n",
    "feature_cnt = [0 for i in range(len(headers))]\n",
    "\n",
    "for i, header in enumerate(headers):\n",
    "    column_names[i] = header\n",
    "    \n",
    "\n",
    "print(column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the validation data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **criterion**: The function to measure the quality of a split. Your model should support `gini` for the Gini impurity and `entropy` for the information gain. \n",
    "2. **max_depth**: The maximum depth of the tree. If `max_depth=None`, then nodes are expanded until all leaves are pure. `max_depth=1` equals to split data once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = x_train_data.to_numpy()\n",
    "y_train_data = y_train_data.to_numpy(dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gini=None, info_gain=None, leaf_pred=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.data_left = data_left\n",
    "        self.data_right = data_right\n",
    "        self.gini = gini\n",
    "        self.info_gain = info_gain\n",
    "        self.leaf_pred = leaf_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        if max_features is not None:\n",
    "            max_features = int(round(max_features))\n",
    "        self.max_features = max_features\n",
    "        self.root = None\n",
    "\n",
    "    def _best_split(self, x_data, y_data):\n",
    "        best_split = {}\n",
    "        best_info_gain = -1\n",
    "        best_gini_gain = -1\n",
    "        # Random choose m features to be the best feature candidates\n",
    "        if self.max_features is not None and self.max_features < x_data.shape[1]:\n",
    "            selected_features = np.random.choice(a=x_data.shape[1], size=self.max_features, replace=False)\n",
    "        else:\n",
    "            selected_features = [i for i in range(x_data.shape[1])]\n",
    "        # for feature in range(len(column_names)):\n",
    "        for feature in selected_features:\n",
    "            feature_values = x_data[:, feature]\n",
    "            for threshold in np.unique(feature_values):\n",
    "\n",
    "                df = np.concatenate((x_data, y_data.reshape(1, -1).T), axis=1)\n",
    "\n",
    "                # category\n",
    "                if column_names[feature] in category:\n",
    "                    df_left = np.array([row for row in df if row[feature] == threshold])\n",
    "                    df_right = np.array([row for row in df if row[feature] != threshold])\n",
    "                # numerical\n",
    "                else:\n",
    "                    df_left = np.array([row for row in df if row[feature] <= threshold])\n",
    "                    df_right = np.array([row for row in df if row[feature] > threshold])\n",
    "\n",
    "                if len(df_left) > 0 and len(df_right) > 0:\n",
    "                    y_data = df[:, -1]\n",
    "                    y_left = df_left[:, -1]\n",
    "                    y_right = df_right[:, -1]\n",
    "\n",
    "                    if self.criterion == 'entropy':\n",
    "                        info_gain = compute_info_gain(y_data, y_left, y_right)\n",
    "                        if info_gain > best_info_gain:\n",
    "                            best_split = {\n",
    "                                'feature_index': feature,\n",
    "                                'threshold': threshold,\n",
    "                                'df_left': df_left,\n",
    "                                'df_right': df_right,\n",
    "                                'gain': info_gain\n",
    "                            }\n",
    "                            best_info_gain = info_gain\n",
    "                            \n",
    "                    elif self.criterion == 'gini':\n",
    "                        gini_gain = compute_gini_gain(y_data, y_left, y_right)\n",
    "                        if gini_gain > best_gini_gain:\n",
    "                            best_split = {\n",
    "                                'feature_index': feature,\n",
    "                                'threshold': threshold,\n",
    "                                'df_left': df_left,\n",
    "                                'df_right': df_right,\n",
    "                                'gini': gini_gain\n",
    "                            }\n",
    "                            best_gini_gain = gini_gain\n",
    "        # Count feature importance\n",
    "        if best_split != {}:\n",
    "            feature_cnt[best_split['feature_index']] += 1\n",
    "\n",
    "        return best_split\n",
    "    \n",
    "    def _build(self, x_data, y_data, cur_depth=0):\n",
    "        # if self.criterion == 'gini' and entropy(y_data) == 0:\n",
    "        #     print(\"gini, entropy = 0\")\n",
    "\n",
    "        # if self.criterion == 'entropy' and entropy(y_data) == 0:\n",
    "        n_rows, n_cols = x_data.shape\n",
    "        if (self.max_depth is None or cur_depth < self.max_depth) and entropy(y_data) != 0 and n_rows >= 2:\n",
    "            best = self._best_split(x_data, y_data)\n",
    "            if best == {}:\n",
    "                return Node(leaf_pred=Counter(y_data).most_common(1)[0][0])\n",
    "            left = self._build(\n",
    "                x_data=best['df_left'][:, :-1], \n",
    "                y_data=best['df_left'][:, -1], \n",
    "                cur_depth=cur_depth + 1\n",
    "            )\n",
    "            right = self._build(\n",
    "                x_data=best['df_right'][:, :-1], \n",
    "                y_data=best['df_right'][:, -1], \n",
    "                cur_depth=cur_depth + 1\n",
    "            )\n",
    "            if self.criterion == 'entropy':\n",
    "                return Node(\n",
    "                    feature=best['feature_index'], \n",
    "                    threshold=best['threshold'], \n",
    "                    data_left=left, \n",
    "                    data_right=right, \n",
    "                    info_gain=best['gain']\n",
    "                )\n",
    "            else:\n",
    "                return Node(\n",
    "                    feature=best['feature_index'], \n",
    "                    threshold=best['threshold'], \n",
    "                    data_left=left, \n",
    "                    data_right=right, \n",
    "                    gini=best['gini']\n",
    "                )\n",
    "\n",
    "        return Node(\n",
    "            leaf_pred=Counter(y_data).most_common(1)[0][0]\n",
    "        )\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        # print(\"x_data.shape = \", x_data.shape)\n",
    "        self.root = self._build(x_data, y_data) # root is a root Node of a tree\n",
    "        \n",
    "    def _predict(self, x, tree):\n",
    "        # Leaf node\n",
    "        if tree.leaf_pred != None:\n",
    "            return tree.leaf_pred\n",
    "        # print(\"x.shape = \", x.shape)\n",
    "        # print(\"tree.feature = \", tree.feature)\n",
    "        feature_value = x[tree.feature]\n",
    "        \n",
    "        # Go to the left\n",
    "        if column_names[tree.feature] in category:\n",
    "            if feature_value == tree.threshold:\n",
    "                return self._predict(x=x, tree=tree.data_left)\n",
    "            else:\n",
    "                return self._predict(x=x, tree=tree.data_right)\n",
    "        else:\n",
    "            if feature_value <= tree.threshold:\n",
    "                return self._predict(x=x, tree=tree.data_left)\n",
    "            \n",
    "            # Go to the right\n",
    "            if feature_value > tree.threshold:\n",
    "                return self._predict(x=x, tree=tree.data_right)\n",
    "        \n",
    "    def predict(self, x_data):\n",
    "        y_pred_data = np.array([self._predict(x, self.root) for x in x_data])\n",
    "        \n",
    "        return y_pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Using `criterion=gini`, showing the accuracy score of validation data by `max_depth=3` and `max_depth=10`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9166666666666666\n",
      "Accuracy =  0.9366666666666666\n"
     ]
    }
   ],
   "source": [
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_depth3.fit(x_train_data, y_train_data)\n",
    "y_pred_data= clf_depth3.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "\n",
    "feature_cnt = [0 for i in range(len(headers))]\n",
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)\n",
    "clf_depth10.fit(x_train_data, y_train_data)\n",
    "y_pred_data= clf_depth10.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy = \", accuracy)\n",
    "saved_feature_cnt = feature_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Using `max_depth=3`, showing the accuracy score of validation data by `criterion=gini` and `criterion=entropy`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy gini =  0.9166666666666666\n",
      "Accuracy entropy =  0.93\n"
     ]
    }
   ],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_gini.fit(x_train_data, y_train_data)\n",
    "y_pred_data= clf_gini.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy gini = \", accuracy)\n",
    "\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)\n",
    "clf_entropy.fit(x_train_data, y_train_data)\n",
    "y_pred_data= clf_entropy.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy entropy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Your decisition tree scores should over **0.9**. It may suffer from overfitting, if so, you can tune the hyperparameter such as `max_depth`\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the **counts of feature used** for building tree without normalize the importance. Take the figure below as example, outlook feature has been used for splitting for almost 50 times. Therefore, it has the largest importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 11, 5, 15, 0, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.barh(headers, saved_feature_cnt)\n",
    "print(saved_feature_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "implement the AdaBooest algorithm by using the CART you just implemented from question 2 as base learner. You should implement one arguments for the AdaBooest.\n",
    "1. **n_estimators**: The maximum number of estimators at which boosting is terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.trees = []\n",
    "        \n",
    "    def fit(self, x_data, y_data):\n",
    "        num_data = x_data.shape[0]\n",
    "        # initialize weight\n",
    "        w = np.repeat(1/num_data, num_data)\n",
    "        # initialize weighted data\n",
    "        x_weighted_data, y_weighted_data = x_data, y_data\n",
    "        # Start T iterations\n",
    "        for i in range(self.n_estimators):\n",
    "            # Generate tree as weak learner\n",
    "            tree = DecisionTree(criterion='gini', max_depth=1)\n",
    "            tree.fit(x_weighted_data, y_weighted_data)\n",
    "            y_pred_data = tree.predict(x_data)  #####################################\n",
    "            # Compute error, alpha as the weight of the weak learner\n",
    "            error = w[y_pred_data != y_data].sum()\n",
    "            alpha = 1/2 * np.log((1-error+1e-10) / (error+1e-10))\n",
    "            # Compute normalized weight of each sample\n",
    "            w = w * np.exp(-alpha * y_pred_data * y_data)\n",
    "            w /= np.sum(w)\n",
    "            # Select samples base on base on normalized weights\n",
    "            choices = np.random.choice(len(x_weighted_data), len(x_weighted_data), p=w, replace=True)\n",
    "            x_weighted_data = x_weighted_data[choices]\n",
    "            y_weighted_data = y_weighted_data[choices]\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def predict(self, x_data):\n",
    "        y_preds = []\n",
    "        for tree in self.trees:\n",
    "            y_preds.append(tree.predict(x_data))\n",
    "        y_preds_swap = np.swapaxes(y_preds, axis1=0, axis2=1)\n",
    "        y_pred_data = []\n",
    "        for y_trees in y_preds_swap:\n",
    "            y_pred_data.append(Counter(y_trees).most_common(1)[0][0])\n",
    "\n",
    "        y_pred_data = np.array(y_pred_data)\n",
    "        # accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "        return y_pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Show the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10 =  0.8433333333333334\n",
      "Accuracy 100 =  0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "adabooster10 = AdaBoost(n_estimators=10)\n",
    "adabooster10.fit(x_train_data, y_train_data)\n",
    "y_pred_data = adabooster10.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy 10 = \", accuracy)\n",
    "\n",
    "adabooster100 = AdaBoost(n_estimators=100)\n",
    "adabooster100.fit(x_train_data, y_train_data)\n",
    "y_pred_data = adabooster100.predict(x_val_data)\n",
    "accuracy100 = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy 100 = \", accuracy100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement three arguments for the Random Forest.\n",
    "\n",
    "1. **n_estimators**: The number of trees in the forest. \n",
    "2. **max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **bootstrap**: Whether bootstrap samples are used when building tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        if max_features is not None:\n",
    "            max_features = int(round(max_features))\n",
    "        self.max_features = max_features\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "\n",
    "    def random_sample(self, x_data, y_data):\n",
    "        num_row, _ = x_data.shape\n",
    "        choices = np.random.choice(a=num_row, size=num_row, replace=True)\n",
    "        x_data = x_data[choices]\n",
    "        y_data = y_data[choices]\n",
    "\n",
    "        return x_data, y_data\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            if self.boostrap:\n",
    "                x_bs_data, y_bs_data = self.random_sample(x_data, y_data)\n",
    "            tree = DecisionTree(criterion=self.criterion, max_depth=self.max_depth, max_features=self.max_features)\n",
    "            tree.fit(x_bs_data, y_bs_data)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "\n",
    "\n",
    "    def predict(self, x_data):\n",
    "            y_preds = [ tree.predict(x_data) for tree in self.trees ]\n",
    "            y_preds_swap = np.swapaxes(a=y_preds, axis1=0, axis2=1)\n",
    "            y_pred_data = []\n",
    "            for y_trees in y_preds_swap:\n",
    "                y_pred_data.append(Counter(y_trees).most_common(1)[0][0])\n",
    "\n",
    "            y_pred_data = np.array(y_pred_data)\n",
    "            return y_pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Using `criterion=gini`, `max_depth=None`, `max_features=sqrt(n_features)`, showing the accuracy score of validation data by `n_estimators=10` and `n_estimators=100`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 10 =  0.9366666666666666\n",
      "Accuracy 100 =  0.9433333333333334\n"
     ]
    }
   ],
   "source": [
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(x_train_data.shape[1]))\n",
    "clf_10tree.fit(x_train_data, y_train_data)\n",
    "y_pred_data = clf_10tree.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy 10 = \", accuracy)\n",
    "\n",
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(x_train_data.shape[1]))\n",
    "clf_100tree.fit(x_train_data, y_train_data)\n",
    "y_pred_data = clf_100tree.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy 100 = \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "Using `criterion=gini`, `max_depth=None`, `n_estimators=10`, showing the accuracy score of validation data by `max_features=sqrt(n_features)` and `max_features=n_features`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy random =  0.93\n",
      "Accuracy all =  0.96\n"
     ]
    }
   ],
   "source": [
    "clf_random_features = RandomForest(n_estimators=10, max_features=np.sqrt(x_train_data.shape[1]))\n",
    "clf_random_features.fit(x_train_data, y_train_data)\n",
    "y_pred_data = clf_random_features.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy random = \", accuracy)\n",
    "\n",
    "clf_all_features = RandomForest(n_estimators=10, max_features=x_train_data.shape[1])\n",
    "clf_all_features.fit(x_train_data, y_train_data)\n",
    "y_pred_data = clf_all_features.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy all = \", accuracy)\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy = accuracy_score(y_val_data, y_pred_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Train and tune your model on a real-world dataset\n",
    "Try you best to get higher accuracy score of your model. After parameter tuning, you can train your model on the full dataset (train + val).\n",
    "- Feature engineering\n",
    "- Hyperparameter tuning\n",
    "- Implement any other ensemble methods, such as gradient boosting. Please note that you **can not** call any package. Also, only ensemble method can be used. Neural network method is not allowed to used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把train model的輸入改好，重新截圖報告要的內容，繳交檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble():\n",
    "    def __init__(self, n_estimators, max_features, boostrap=True, criterion='gini', max_depth=None, feature_engineering=False):\n",
    "        self.n_estimators = n_estimators\n",
    "        if max_features is not None:\n",
    "            max_features = int(round(max_features))\n",
    "        self.max_features = max_features\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_engineering = feature_engineering\n",
    "        self.trees = []\n",
    "\n",
    "\n",
    "    def random_sample(self, x_data, y_data):\n",
    "        num_row, _ = x_data.shape\n",
    "        choices = np.random.choice(a=num_row, size=num_row, replace=True)\n",
    "        x_data = x_data[choices]\n",
    "        y_data = y_data[choices]\n",
    "\n",
    "        return x_data, y_data\n",
    "\n",
    "    def fit(self, x_data, y_data):\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            if self.boostrap:\n",
    "                x_bs_data, y_bs_data = self.random_sample(x_data, y_data)\n",
    "            tree = DecisionTree(criterion=self.criterion, max_depth=self.max_depth, max_features=self.max_features)\n",
    "            tree.fit(x_bs_data, y_bs_data)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        if self.feature_engineering:\n",
    "            width_times_height = np.expand_dims(x_data[:,11] * x_data[:,12], axis=1)\n",
    "            battery_times_RAM = np.expand_dims(x_data[:,0] * x_data[:,13], axis=1)\n",
    "            x_data = np.concatenate((x_data, width_times_height, battery_times_RAM), axis=1)\n",
    "        \n",
    "        y_preds = [ tree.predict(x_data) for tree in self.trees ]\n",
    "        y_preds_swap = np.swapaxes(a=y_preds, axis1=0, axis2=1)\n",
    "        y_pred_data = []\n",
    "        for y_trees in y_preds_swap:\n",
    "            y_pred_data.append(Counter(y_trees).most_common(1)[0][0])\n",
    "\n",
    "        y_pred_data = np.array(y_pred_data)\n",
    "        return y_pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_your_model(trainval_df): # WRONG\n",
    "    x_train_data = trainval_df.drop(\"price_range\", axis=1).to_numpy()\n",
    "    y_train_data = trainval_df[\"price_range\"].to_numpy()\n",
    "    \n",
    "    \n",
    "    my_model = Ensemble(n_estimators=150, criterion='gini', max_depth=None, max_features=x_train_data.shape[1], feature_engineering=True) #np.sqrt(x_train_new.shape[1])) # x_train_new.shape[1] + \n",
    "    my_model.fit(x_train_data, y_train_data)\n",
    "    \n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = train_your_model(trainval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy random =  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_data = my_model.predict(x_train_data)\n",
    "accuracy = (y_train_data == y_pred_data).sum() / len(y_train_data)\n",
    "print(\"Accuracy random = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "my_model7 = pickle.load(open(\"model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy random =  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_data = my_model7.predict(x_val_data)\n",
    "accuracy = (y_val_data == y_pred_data).sum() / len(y_val_data)\n",
    "print(\"Accuracy random = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(my_model, open('model.pkl', 'wb'))\n",
    "np.save(\"y_pred.npy\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "loaded = np.load(\"y_pred.npy\")\n",
    "print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT MODIFY CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 3\u001b[0m y_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39my_test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mprice_range\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest-set accuarcy score: \u001b[39m\u001b[39m'\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Terry\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('y_test.csv')['price_range'].values\n",
    "\n",
    "print('Test-set accuarcy score: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** We will check your result for Question 3 manually *** (5 points)\n",
      "*** We will check your result for Question 6 manually *** (20 points)\n",
      "Approximate score range: 45.0 ~ 70.0\n",
      "*** This score is only for reference ***\n"
     ]
    }
   ],
   "source": [
    "def discrete_checker(score, thres, clf, name, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "        return score\n",
    "    else:\n",
    "        print(f\"{name} failed\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def patient_checker(score, thres, CLS, kwargs, name,\n",
    "                    x_train, y_train, x_test, y_test, patient=10):\n",
    "    while patient > 0:\n",
    "        patient -= 1\n",
    "        clf = CLS(**kwargs)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        if accuracy_score(y_test, y_pred) - thres >= 0:\n",
    "            return score\n",
    "    print(f\"{name} failed\")\n",
    "    print(\"Considering the randomness, we will check it manually\")\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\"\n",
    "    df = pd.read_csv(\n",
    "        file_url,\n",
    "        names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "               \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
    "    )\n",
    "\n",
    "    df['Target'] = (df[\"Age\"] > 15).astype(int)\n",
    "    df = df.drop(labels=[\"Age\"], axis=\"columns\")\n",
    "\n",
    "    train_idx = range(0, len(df), 10)\n",
    "    test_idx = range(1, len(df), 20)\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "    x_train = train_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    feature_names = x_train.columns.values\n",
    "    x_train = x_train.values\n",
    "    y_train = train_df['Target'].values\n",
    "\n",
    "    x_test = test_df.drop(labels=[\"Target\"], axis=\"columns\")\n",
    "    x_test = x_test.values\n",
    "    y_test = test_df['Target'].values\n",
    "    return x_train, y_train, x_test, y_test, feature_names\n",
    "\n",
    "\n",
    "score = 0\n",
    "\n",
    "data = np.array([1, 2])\n",
    "if abs(gini(data) - 0.5) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"gini test failed\")\n",
    "\n",
    "if abs(entropy(data) - 1) < 1e-4:\n",
    "    score += 2.5\n",
    "else:\n",
    "    print(\"entropy test failed\")\n",
    "\n",
    "x_train, y_train, x_test, y_test, feature_names = load_dataset()\n",
    "\n",
    "score += discrete_checker(5, 0.9337,\n",
    "                          DecisionTree(criterion='gini', max_depth=3),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9036,\n",
    "                          DecisionTree(criterion='gini', max_depth=10),\n",
    "                          \"DecisionTree(criterion='gini', max_depth=10)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "score += discrete_checker(2.5, 0.9096,\n",
    "                          DecisionTree(criterion='entropy', max_depth=3),\n",
    "                          \"DecisionTree(criterion='entropy', max_depth=3)\",\n",
    "                          x_train, y_train, x_test, y_test\n",
    "                          )\n",
    "\n",
    "print(\"*** We will check your result for Question 3 manually *** (5 points)\")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.91, AdaBoost, {\"n_estimators\": 10},\n",
    "    \"AdaBoost(n_estimators=10)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    7.5, 0.87, AdaBoost, {\"n_estimators\": 100},\n",
    "    \"AdaBoost(n_estimators=100)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=10, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.91, RandomForest,\n",
    "    {\"n_estimators\": 100, \"max_features\": np.sqrt(x_train.shape[1])},\n",
    "    \"RandomForest(n_estimators=100, max_features=sqrt(n_features))\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "score += patient_checker(\n",
    "    5, 0.92, RandomForest,\n",
    "    {\"n_estimators\": 10, \"max_features\": x_train.shape[1]},\n",
    "    \"RandomForest(n_estimators=10, max_features=n_features)\",\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "print(\"*** We will check your result for Question 6 manually *** (20 points)\")\n",
    "print(\"Approximate score range:\", score, \"~\", score + 25)\n",
    "print(\"*** This score is only for reference ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2cefb6477faab595c65c4416ff83d6c7b73571d0f54d603d29c372c95ba24cd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
