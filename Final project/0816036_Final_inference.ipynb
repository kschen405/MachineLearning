{"cells":[{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2023-01-03T16:24:56.244687Z","iopub.status.busy":"2023-01-03T16:24:56.243824Z","iopub.status.idle":"2023-01-03T16:25:14.387226Z","shell.execute_reply":"2023-01-03T16:25:14.385865Z","shell.execute_reply.started":"2023-01-03T16:24:56.244588Z"},"trusted":true},"outputs":[],"source":["# pip install feature_engine\n","# pip install imblearn\n","# pip install gdown\n","\n","import gdown\n","url = \"https://drive.google.com/drive/u/1/folders/1RQuymJleFRULtzlSPOUOtA6ah1onITu-\"\n","gdown.download_folder(url, quiet=True, use_cookies=False)\n","\n","import numpy as np\n","import pandas as pd\n","from feature_engine.encoding import WoEEncoder\n","import random\n","from sklearn.linear_model import HuberRegressor, LogisticRegression\n","from sklearn.impute import KNNImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","from imblearn.over_sampling import SMOTE\n","import pickle\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Load data"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["26570\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>...</th>\n","      <th>measurement_8</th>\n","      <th>measurement_9</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>80.10</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>20.155</td>\n","      <td>10.672</td>\n","      <td>15.859</td>\n","      <td>17.594</td>\n","      <td>15.193</td>\n","      <td>15.029</td>\n","      <td>NaN</td>\n","      <td>13.034</td>\n","      <td>14.684</td>\n","      <td>764.100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>84.89</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>14</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>17.889</td>\n","      <td>12.448</td>\n","      <td>17.947</td>\n","      <td>17.915</td>\n","      <td>11.755</td>\n","      <td>14.732</td>\n","      <td>15.425</td>\n","      <td>14.395</td>\n","      <td>15.631</td>\n","      <td>682.057</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 25 columns</p>\n","</div>"],"text/plain":["   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n","0   0            A    80.10  material_7  material_8            9            5   \n","1   1            A    84.89  material_7  material_8            9            5   \n","\n","   measurement_0  measurement_1  measurement_2  ...  measurement_8  \\\n","0              7              8              4  ...         20.155   \n","1             14              3              3  ...         17.889   \n","\n","   measurement_9  measurement_10  measurement_11  measurement_12  \\\n","0         10.672          15.859          17.594          15.193   \n","1         12.448          17.947          17.915          11.755   \n","\n","   measurement_13  measurement_14  measurement_15  measurement_16  \\\n","0          15.029             NaN          13.034          14.684   \n","1          14.732          15.425          14.395          15.631   \n","\n","   measurement_17  \n","0         764.100  \n","1         682.057  \n","\n","[2 rows x 25 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train.shape = (26570, 25)\n","test.shape = (20775, 25)\n","test.shape = (47345, 25)\n"]}],"source":["train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")\n","\n","train_labels = train.pop('failure')\n","print(len(train_labels))\n","train_test = pd.concat([train, test])\n","display(train.head(2))\n","print(f'train.shape = {train.shape}')\n","print(f'test.shape = {test.shape}')\n","print(f'test.shape = {train_test.shape}')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Compute missing columns for measurement 3 and 5"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>...</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>missing_3</th>\n","      <th>missing_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>80.10</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>15.859</td>\n","      <td>17.594</td>\n","      <td>15.193</td>\n","      <td>15.029</td>\n","      <td>NaN</td>\n","      <td>13.034</td>\n","      <td>14.684</td>\n","      <td>764.100</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>84.89</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>14</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>17.947</td>\n","      <td>17.915</td>\n","      <td>11.755</td>\n","      <td>14.732</td>\n","      <td>15.425</td>\n","      <td>14.395</td>\n","      <td>15.631</td>\n","      <td>682.057</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 27 columns</p>\n","</div>"],"text/plain":["   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n","0   0            A    80.10  material_7  material_8            9            5   \n","1   1            A    84.89  material_7  material_8            9            5   \n","\n","   measurement_0  measurement_1  measurement_2  ...  measurement_10  \\\n","0              7              8              4  ...          15.859   \n","1             14              3              3  ...          17.947   \n","\n","   measurement_11  measurement_12  measurement_13  measurement_14  \\\n","0          17.594          15.193          15.029             NaN   \n","1          17.915          11.755          14.732          15.425   \n","\n","   measurement_15  measurement_16  measurement_17  missing_3  missing_5  \n","0          13.034          14.684         764.100      False      False  \n","1          14.395          15.631         682.057      False      False  \n","\n","[2 rows x 27 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["missing 3 = 710/47345\n","missing 5 = 1184/47345\n"]}],"source":["train_test['missing_3'] = train_test['measurement_3'].isna()\n","train_test['missing_5'] = train_test['measurement_5'].isna()\n","display(train_test.head(2))\n","print(f\"missing 3 = {train_test['missing_3'].sum()}/{len(train_test['missing_3'])}\")\n","print(f\"missing 5 = {train_test['missing_5'].sum()}/{len(train_test['missing_5'])}\")"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["category_features = ['attribute_0', 'attribute_1', 'attribute_2', 'attribute_3']\n","numerical_features = ['loading', 'measurement_0', 'measurement_1', 'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17']\n"]}],"source":["category_features = [ col for col in train.columns if col.startswith('attribute_')]\n","numerical_features = [ col for col in train.columns if col.startswith('measurement_') or col == 'loading']\n","print(f'category_features = {category_features}')\n","print(f'numerical_features = {numerical_features}')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Calculate the highest absolute correlations for each feature"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["fill_dict = {\n","    'A': ['measurement_5','measurement_6','measurement_8'],\n","    'B': ['measurement_4','measurement_5','measurement_7'],\n","    'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n","    'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n","    'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n","    'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n","    'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n","    'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n","    'I': ['measurement_3','measurement_7','measurement_8']\n","}"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['measurement_4', 'measurement_5', 'measurement_7', 'measurement_8', 'measurement_9']\n"]}],"source":["product_feature_corr = {}\n","for product_code in train_test['product_code'].unique():\n","    product_data = train_test[ train_test['product_code'] == product_code ]\n","    feature_corr = {}\n","    for n_feature in numerical_features:\n","        abs_corr = np.abs(product_data[numerical_features].corr()[n_feature])\n","        sort_abs_corr = abs_corr.sort_values(ascending=False)\n","        feature_corr[n_feature] = sort_abs_corr[1:5].index.to_list() #, sort_abs_corr[1:5].to_list())\n","    \n","    product_feature_corr[product_code] = feature_corr\n","\n","for product_code in train_test['product_code'].unique():\n","    product_feature_corr[product_code]['measurement_17'] = fill_dict[product_code]\n","\n","\n","# print(product_feature_corr['A']['measurement_0'])\n","print(product_feature_corr['H']['measurement_17'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Fill in Nan by HuberRegressor or KNNImputer"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nan:  49\n","Huber fill:  41\n","Number of nan:  68\n","Huber fill:  56\n","Number of nan:  102\n","Huber fill:  72\n","Number of nan:  151\n","Huber fill:  113\n","Number of nan:  175\n","Huber fill:  146\n","Number of nan:  176\n","Huber fill:  134\n","Number of nan:  187\n","Huber fill:  167\n","Number of nan:  225\n","Huber fill:  190\n","Number of nan:  257\n","Huber fill:  189\n","Number of nan:  296\n","Huber fill:  225\n","Number of nan:  326\n","Huber fill:  234\n","Number of nan:  330\n","Huber fill:  266\n","Number of nan:  316\n","Huber fill:  237\n","Number of nan:  377\n","Huber fill:  273\n","Number of nan:  388\n","Huber fill:  293\n","Number of nan:  426\n","Huber fill:  386\n","Number of nan:  41\n","Huber fill:  35\n","Number of nan:  84\n","Huber fill:  72\n","Number of nan:  95\n","Huber fill:  80\n","Number of nan:  115\n","Huber fill:  89\n","Number of nan:  133\n","Huber fill:  113\n","Number of nan:  193\n","Huber fill:  167\n","Number of nan:  212\n","Huber fill:  168\n","Number of nan:  251\n","Huber fill:  207\n","Number of nan:  267\n","Huber fill:  197\n","Number of nan:  287\n","Huber fill:  220\n","Number of nan:  298\n","Huber fill:  250\n","Number of nan:  361\n","Huber fill:  269\n","Number of nan:  341\n","Huber fill:  314\n","Number of nan:  388\n","Huber fill:  294\n","Number of nan:  459\n","Huber fill:  358\n","Number of nan:  450\n","Huber fill:  418\n","Number of nan:  49\n","Huber fill:  45\n","Number of nan:  76\n","Huber fill:  63\n","Number of nan:  123\n","Huber fill:  104\n","Number of nan:  162\n","Huber fill:  141\n","Number of nan:  182\n","Huber fill:  141\n","Number of nan:  192\n","Huber fill:  140\n","Number of nan:  242\n","Huber fill:  189\n","Number of nan:  270\n","Huber fill:  232\n","Number of nan:  281\n","Huber fill:  256\n","Number of nan:  296\n","Huber fill:  231\n","Number of nan:  333\n","Huber fill:  258\n","Number of nan:  361\n","Huber fill:  309\n","Number of nan:  428\n","Huber fill:  330\n","Number of nan:  438\n","Huber fill:  319\n","Number of nan:  442\n","Huber fill:  343\n","Number of nan:  469\n","Huber fill:  391\n","Number of nan:  49\n","Huber fill:  33\n","Number of nan:  69\n","Huber fill:  58\n","Number of nan:  96\n","Huber fill:  86\n","Number of nan:  111\n","Huber fill:  87\n","Number of nan:  156\n","Huber fill:  118\n","Number of nan:  171\n","Huber fill:  146\n","Number of nan:  195\n","Huber fill:  134\n","Number of nan:  238\n","Huber fill:  198\n","Number of nan:  241\n","Huber fill:  174\n","Number of nan:  288\n","Huber fill:  264\n","Number of nan:  314\n","Huber fill:  232\n","Number of nan:  379\n","Huber fill:  323\n","Number of nan:  392\n","Huber fill:  293\n","Number of nan:  406\n","Huber fill:  313\n","Number of nan:  402\n","Huber fill:  322\n","Number of nan:  466\n","Huber fill:  398\n","Number of nan:  62\n","Huber fill:  49\n","Number of nan:  84\n","Huber fill:  65\n","Number of nan:  122\n","Huber fill:  105\n","Number of nan:  137\n","Huber fill:  113\n","Number of nan:  150\n","Huber fill:  120\n","Number of nan:  205\n","Huber fill:  172\n","Number of nan:  212\n","Huber fill:  171\n","Number of nan:  243\n","Huber fill:  191\n","Number of nan:  254\n","Huber fill:  193\n","Number of nan:  301\n","Huber fill:  244\n","Number of nan:  330\n","Huber fill:  247\n","Number of nan:  343\n","Huber fill:  292\n","Number of nan:  397\n","Huber fill:  297\n","Number of nan:  400\n","Huber fill:  315\n","Number of nan:  419\n","Huber fill:  316\n","Number of nan:  473\n","Huber fill:  429\n","Number of nan:  67\n","Huber fill:  52\n","Number of nan:  77\n","Huber fill:  62\n","Number of nan:  110\n","Huber fill:  86\n","Number of nan:  121\n","Huber fill:  90\n","Number of nan:  164\n","Huber fill:  137\n","Number of nan:  176\n","Huber fill:  147\n","Number of nan:  221\n","Huber fill:  194\n","Number of nan:  236\n","Huber fill:  211\n","Number of nan:  239\n","Huber fill:  186\n","Number of nan:  285\n","Huber fill:  226\n","Number of nan:  341\n","Huber fill:  289\n","Number of nan:  329\n","Huber fill:  251\n","Number of nan:  380\n","Huber fill:  327\n","Number of nan:  408\n","Huber fill:  333\n","Number of nan:  456\n","Huber fill:  356\n","Number of nan:  463\n","Huber fill:  420\n","Number of nan:  49\n","Huber fill:  43\n","Number of nan:  88\n","Huber fill:  77\n","Number of nan:  117\n","Huber fill:  92\n","Number of nan:  126\n","Huber fill:  104\n","Number of nan:  162\n","Huber fill:  146\n","Number of nan:  166\n","Huber fill:  145\n","Number of nan:  218\n","Huber fill:  187\n","Number of nan:  209\n","Huber fill:  156\n","Number of nan:  292\n","Huber fill:  226\n","Number of nan:  307\n","Huber fill:  221\n","Number of nan:  312\n","Huber fill:  251\n","Number of nan:  309\n","Huber fill:  289\n","Number of nan:  341\n","Huber fill:  268\n","Number of nan:  360\n","Huber fill:  299\n","Number of nan:  438\n","Huber fill:  343\n","Number of nan:  430\n","Huber fill:  373\n","Number of nan:  51\n","Huber fill:  46\n","Number of nan:  85\n","Huber fill:  77\n","Number of nan:  88\n","Huber fill:  75\n","Number of nan:  137\n","Huber fill:  117\n","Number of nan:  150\n","Huber fill:  110\n","Number of nan:  195\n","Huber fill:  148\n","Number of nan:  188\n","Huber fill:  147\n","Number of nan:  232\n","Huber fill:  187\n","Number of nan:  269\n","Huber fill:  204\n","Number of nan:  277\n","Huber fill:  205\n","Number of nan:  310\n","Huber fill:  244\n","Number of nan:  324\n","Huber fill:  272\n","Number of nan:  354\n","Huber fill:  283\n","Number of nan:  387\n","Huber fill:  299\n","Number of nan:  403\n","Huber fill:  340\n","Number of nan:  433\n","Huber fill:  361\n","Number of nan:  56\n","Huber fill:  47\n","Number of nan:  79\n","Huber fill:  67\n","Number of nan:  94\n","Huber fill:  84\n","Number of nan:  124\n","Huber fill:  111\n","Number of nan:  148\n","Huber fill:  115\n","Number of nan:  183\n","Huber fill:  136\n","Number of nan:  219\n","Huber fill:  192\n","Number of nan:  227\n","Huber fill:  192\n","Number of nan:  267\n","Huber fill:  240\n","Number of nan:  267\n","Huber fill:  209\n","Number of nan:  277\n","Huber fill:  213\n","Number of nan:  341\n","Huber fill:  272\n","Number of nan:  365\n","Huber fill:  283\n","Number of nan:  387\n","Huber fill:  334\n","Number of nan:  381\n","Huber fill:  294\n","Number of nan:  414\n","Huber fill:  377\n"]}],"source":["\n","for product_code in train_test['product_code'].unique():\n","    product_data = train_test[ train_test['product_code'] == product_code ]\n","    for n_feature in numerical_features:\n","        corr_features = product_feature_corr[product_code][n_feature]\n","        if product_data[n_feature].isna().sum() != 0:\n","            print(\"Number of nan: \", product_data[n_feature].isna().sum())\n","\n","            # HuberRegressor\n","            # target: clean, corr: clean\n","            huber_fit_data = product_data[ [n_feature] + corr_features].dropna(axis=0, how='any')\n","            # target: NaN, corr: clean\n","            huber_predict_data = product_data[ product_data[n_feature].isna() & (product_data[corr_features].isna().sum(axis=1) == 0)]\n","            print(\"Huber fill: \", huber_predict_data.shape[0])\n","            huber = HuberRegressor(epsilon=1.9)\n","            huber.fit(X=huber_fit_data[corr_features], y=huber_fit_data[n_feature])\n","            # Bottleneck: might not hold\n","            product_data[ product_data[n_feature].isna() & (product_data[corr_features].isna().sum(axis=1) == 0)][n_feature] = huber.predict(huber_predict_data[corr_features])  \n","\n","    \n","    # KNNImputer\n","    imputer = KNNImputer(n_neighbors=20)\n","    product_data[numerical_features] = imputer.fit_transform(product_data[numerical_features])\n","    # print(product_data[numerical_features].isna().sum().sum())\n","    # Saved updated data to train_test\n","    train_test[ train_test['product_code'] == product_code ] = product_data\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n","0   0            A    80.10  material_7  material_8            9            5   \n","1   1            A    84.89  material_7  material_8            9            5   \n","2   2            A    82.43  material_7  material_8            9            5   \n","3   3            A   101.07  material_7  material_8            9            5   \n","4   4            A   188.06  material_7  material_8            9            5   \n","\n","   measurement_0  measurement_1  measurement_2  ...  measurement_10  \\\n","0              7              8              4  ...          15.859   \n","1             14              3              3  ...          17.947   \n","2             12              1              5  ...          15.607   \n","3             13              2              6  ...          16.346   \n","4              9              2              8  ...          17.082   \n","\n","   measurement_11  measurement_12  measurement_13  measurement_14  \\\n","0          17.594          15.193          15.029        15.57505   \n","1          17.915          11.755          14.732        15.42500   \n","2          19.478          13.798          16.711        18.63100   \n","3          18.377          10.020          15.250        15.56200   \n","4          19.932          12.428          16.182        12.76000   \n","\n","   measurement_15  measurement_16  measurement_17  missing_3  missing_5  \n","0          13.034          14.684         764.100      False      False  \n","1          14.395          15.631         682.057      False      False  \n","2          14.094          17.946         663.376      False      False  \n","3          16.154          17.172         826.282      False      False  \n","4          13.153          16.412         579.885      False      False  \n","\n","[5 rows x 27 columns]\n","(47345, 27)\n"]}],"source":["print(train_test.head())\n","print(train_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Normalization"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>...</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>missing_3</th>\n","      <th>missing_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>-1.224768</td>\n","      <td>material_7</td>\n","      <td>material_8</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>-0.103287</td>\n","      <td>-0.129328</td>\n","      <td>-0.619559</td>\n","      <td>...</td>\n","      <td>-0.180774</td>\n","      <td>-0.944901</td>\n","      <td>2.428971</td>\n","      <td>-0.543637</td>\n","      <td>-0.358955</td>\n","      <td>-1.34843</td>\n","      <td>-1.143312</td>\n","      <td>0.516183</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 27 columns</p>\n","</div>"],"text/plain":["   id product_code   loading attribute_0 attribute_1  attribute_2  \\\n","0   0            A -1.224768  material_7  material_8            9   \n","\n","   attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n","0            5      -0.103287      -0.129328      -0.619559  ...   \n","\n","   measurement_10  measurement_11  measurement_12  measurement_13  \\\n","0       -0.180774       -0.944901        2.428971       -0.543637   \n","\n","   measurement_14  measurement_15  measurement_16  measurement_17  missing_3  \\\n","0       -0.358955        -1.34843       -1.143312        0.516183      False   \n","\n","   missing_5  \n","0      False  \n","\n","[1 rows x 27 columns]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["def normalized(data_df: pd.DataFrame, numerical_features: list):\n","    scaler = StandardScaler()\n","    normalized_data_df = data_df.copy()\n","    normalized_data_df[numerical_features] = scaler.fit_transform(data_df[numerical_features])\n","    # print(normalized_data_df.head(1))\n","    return normalized_data_df\n","\n","normalized_train_test = pd.DataFrame(normalized(train_test, numerical_features), columns=train_test.columns)\n","normalized_train_test.head(1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Split train, test back to original"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["normalized_train_test = normalized_train_test.astype({'attribute_2': object, 'attribute_3': object})\n","train_filled = normalized_train_test.iloc[: train.shape[0], :]\n","test_filled = normalized_train_test.iloc[train.shape[0] :, :]\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Encode \"object\" type columns"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>product_code</th>\n","      <th>loading</th>\n","      <th>attribute_0</th>\n","      <th>attribute_1</th>\n","      <th>attribute_2</th>\n","      <th>attribute_3</th>\n","      <th>measurement_0</th>\n","      <th>measurement_1</th>\n","      <th>measurement_2</th>\n","      <th>...</th>\n","      <th>measurement_10</th>\n","      <th>measurement_11</th>\n","      <th>measurement_12</th>\n","      <th>measurement_13</th>\n","      <th>measurement_14</th>\n","      <th>measurement_15</th>\n","      <th>measurement_16</th>\n","      <th>measurement_17</th>\n","      <th>missing_3</th>\n","      <th>missing_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>-1.224768</td>\n","      <td>0.017894</td>\n","      <td>0.037537</td>\n","      <td>0.085398</td>\n","      <td>0.085398</td>\n","      <td>-0.103287</td>\n","      <td>-0.129328</td>\n","      <td>-0.619559</td>\n","      <td>...</td>\n","      <td>-0.180774</td>\n","      <td>-0.944901</td>\n","      <td>2.428971</td>\n","      <td>-0.543637</td>\n","      <td>-0.358955</td>\n","      <td>-1.348430</td>\n","      <td>-1.143312</td>\n","      <td>0.516183</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>-1.101624</td>\n","      <td>0.017894</td>\n","      <td>0.037537</td>\n","      <td>0.085398</td>\n","      <td>0.085398</td>\n","      <td>1.568709</td>\n","      <td>-1.299094</td>\n","      <td>-0.901217</td>\n","      <td>...</td>\n","      <td>1.265554</td>\n","      <td>-0.733789</td>\n","      <td>-0.028075</td>\n","      <td>-0.788980</td>\n","      <td>-0.465462</td>\n","      <td>-0.438603</td>\n","      <td>-0.558464</td>\n","      <td>-0.160361</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 27 columns</p>\n","</div>"],"text/plain":["   id product_code   loading  attribute_0  attribute_1  attribute_2  \\\n","0   0            A -1.224768     0.017894     0.037537     0.085398   \n","1   1            A -1.101624     0.017894     0.037537     0.085398   \n","\n","   attribute_3  measurement_0  measurement_1  measurement_2  ...  \\\n","0     0.085398      -0.103287      -0.129328      -0.619559  ...   \n","1     0.085398       1.568709      -1.299094      -0.901217  ...   \n","\n","   measurement_10  measurement_11  measurement_12  measurement_13  \\\n","0       -0.180774       -0.944901        2.428971       -0.543637   \n","1        1.265554       -0.733789       -0.028075       -0.788980   \n","\n","   measurement_14  measurement_15  measurement_16  measurement_17  missing_3  \\\n","0       -0.358955       -1.348430       -1.143312        0.516183      False   \n","1       -0.465462       -0.438603       -0.558464       -0.160361      False   \n","\n","   missing_5  \n","0      False  \n","1      False  \n","\n","[2 rows x 27 columns]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# Encode only category_features\n","woe_encoder = WoEEncoder(variables=category_features)\n","train_filled = woe_encoder.fit_transform(X=train_filled, y=train_labels)\n","test_filled = woe_encoder.transform(X=test_filled)\n","train_filled.head(2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Logistic regression & K fold"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["from operator import add\n","\n","def weighted_answer(kfold_val_acc_lst):\n","    weighted_prob_lst = []\n","    for i in range(len(kfold_val_acc_lst[0])):\n","        # weighted_prob_lst.append(kfold_val_acc_lst[0][i]*0.3325 + kfold_val_acc_lst[1][i]*0.6675)\n","        weighted_prob_lst.append(kfold_val_acc_lst[0][i]*0.2 + kfold_val_acc_lst[1][i]*0.25 + kfold_val_acc_lst[2][i]*0.25 + kfold_val_acc_lst[3][i]*0.3)\n","    return weighted_prob_lst"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully load clf0_0.pickle\n","val acc =  0.59541\n","Successfully load clf0_1.pickle\n","val acc =  0.59262\n","Avg accuracy = 0.59402\n","Successfully load clf1_0.pickle\n","val acc =  0.59691\n","Successfully load clf1_1.pickle\n","val acc =  0.59654\n","Avg accuracy = 0.59673\n","Successfully load clf2_0.pickle\n","val acc =  0.59578\n","Successfully load clf2_1.pickle\n","val acc =  0.59699\n","Avg accuracy = 0.59639\n","Successfully load clf3_0.pickle\n","val acc =  0.59518\n","Successfully load clf3_1.pickle\n","val acc =  0.59729\n","Avg accuracy = 0.59624\n"]}],"source":["num_split = 2\n","skf = StratifiedKFold(n_splits=num_split, shuffle=True, random_state=0)\n","sm = SMOTE(random_state = 42, n_jobs = -1)\n","\n","\n","# features = numerical_features\n","features1 = ['missing_3', 'missing_5', 'measurement_1', 'measurement_2', 'loading', 'measurement_17']\n","features2 = ['missing_3', 'missing_5', 'loading', 'measurement_17']\n","features3 = ['missing_3', 'missing_5', 'measurement_2', 'loading', 'measurement_17']\n","features4 = ['measurement_2', 'loading', 'measurement_17']\n","ensemble_features = [features1, features2, features3, features4]\n","\n","feature_importance = []\n","kfold_val_prob_lst = []\n","for n, features in enumerate(ensemble_features):\n","    answer = np.zeros(test_filled.shape[0])\n","    kfold_val_acc = 0\n","    for i, (train_index, val_index) in enumerate(skf.split(train_filled, train_labels)):\n","        # Get index\n","        train_data = train_filled.iloc[train_index][features].reset_index(drop=True)\n","        train_label_data = train_labels[train_index]\n","        val_data = train_filled.iloc[val_index][features].reset_index(drop=True)\n","        val_label_data = train_labels[val_index]\n","        # SMOTE oversampling\n","        train_data, train_label_data = sm.fit_resample(train_data, train_label_data)\n","        # Logistic regerssion\n","        clf = LogisticRegression(max_iter=1000, C=0.0001, penalty='l2',solver='newton-cg')\n","        clf = pickle.load(open(f'./saved_model/clf{n}_{i}.pickle', \"rb\"))\n","        print(f\"Successfully load clf{n}_{i}.pickle\")\n","        # clf.fit(train_data, train_label_data)\n","        # pickle.dump(clf, open(f\"./saved_model/clf{n}_{i}.pickle\", \"wb\"))\n","\n","        val_pred = clf.predict(val_data[features])\n","        val_acc = accuracy_score(val_label_data, val_pred)\n","        kfold_val_acc += val_acc / num_split\n","        print(\"val acc = \", round(val_acc,5))\n","        answer += clf.predict_proba(test_filled[features])[:, 1] / num_split\n","\n","    kfold_val_prob_lst.append(answer)\n","    print(f\"Avg accuracy = {round(kfold_val_acc, 5)}\")\n","weighted_val_answer = weighted_answer(kfold_val_prob_lst)\n","weighted_val_binary_answer = [int(prob > 0.5) for prob in weighted_val_answer]\n","# val_acc = accuracy_score(val_label_data, weighted_val_pred)   answer or val\n","# print(f'weighted_ave_acc = {weighted_val_binary_answer}')"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["sub_log = pd.read_csv('sample_submission.csv')\n","sub_log['failure'] = weighted_val_answer\n","\n","sub_log.to_csv(\"0816036.csv\", index=False)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Load model"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# loaded_model = pickle.load(open('saved_model\\clf1_0.pickle', \"rb\"))\n","# loaded_model"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# STOP"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Combine sm and w/o sm predictions"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# sub_59002 = pd.read_csv('submission_0.59017.csv')\n","# sub_59017 = pd.read_csv('submission_0.59017_0.33_002_0.67_023.csv')\n","# new_sub = sub_59002\n","# new_sub['failure'] = [value59002*0.5 + value59017*0.5 for value59002, value59017 in zip(sub_59002['failure'], sub_59017['failure'])]\n","# new_sub.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"test","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"29931e1b5fd008239d71c860573e1ff80df036f9c7b6fafc66d2e0549fca9a87"}}},"nbformat":4,"nbformat_minor":4}
