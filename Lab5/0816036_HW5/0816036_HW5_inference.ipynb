{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1b25dc0",
   "metadata": {},
   "source": [
    "# Inference part is at the bottom\n",
    "# Click \"run all\" to inference\n",
    "# This code will NOT train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e9d68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from PIL import Image\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import  ConcatDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torchvision.models import wide_resnet50_2, Wide_ResNet50_2_Weights\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8149c80b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:23.963305Z",
     "iopub.status.busy": "2022-11-25T04:50:23.962647Z",
     "iopub.status.idle": "2022-11-25T04:50:30.869958Z",
     "shell.execute_reply": "2022-11-25T04:50:30.868519Z"
    },
    "papermill": {
     "duration": 6.916649,
     "end_time": "2022-11-25T04:50:30.872717",
     "exception": false,
     "start_time": "2022-11-25T04:50:23.956068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./0816036_HW5.docx\n",
      "./0816036_HW5_inference.ipynb\n",
      "./0816036_HW5_train.ipynb\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dirname, _, filenames in os.walk('./'):\n",
    "    for filename in filenames[:3]:\n",
    "        print(os.path.join(dirname, filename))\n",
    "    if len(filenames) > 3:\n",
    "        print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4258a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211b439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52fada5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:32.995956Z",
     "iopub.status.busy": "2022-11-25T04:50:32.994774Z",
     "iopub.status.idle": "2022-11-25T04:50:33.001735Z",
     "shell.execute_reply": "2022-11-25T04:50:33.000477Z"
    },
    "papermill": {
     "duration": 0.014176,
     "end_time": "2022-11-25T04:50:33.004252",
     "exception": false,
     "start_time": "2022-11-25T04:50:32.990076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./train\"\n",
    "TEST_PATH = \"./test\"\n",
    "device = \"cuda\"\n",
    "# try device = \"cuda\" \n",
    "# and change your settings/accelerator to GPU if you want it to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03cb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms_unnormalized = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "AutoAugment_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.AutoAugment(transforms.AutoAugmentPolicy.SVHN),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ColorJitter_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "RandomPerspective_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomPerspective(distortion_scale=0.4, p=1.0),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b6db42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.012917Z",
     "iopub.status.busy": "2022-11-25T04:50:33.012513Z",
     "iopub.status.idle": "2022-11-25T04:50:33.023305Z",
     "shell.execute_reply": "2022-11-25T04:50:33.021968Z"
    },
    "papermill": {
     "duration": 0.017781,
     "end_time": "2022-11-25T04:50:33.025650",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.007869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# data: all train/test file path\n",
    "# self.data: select specific task\n",
    "# self.root: ./train or ./test\n",
    "\n",
    "# Task 1\n",
    "class Task1_Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False, transform=None):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img_path = f\"{self.root}/{filename}\"\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        if self.return_filename: # Normalization\n",
    "            return torch.FloatTensor(img_transformed ), filename\n",
    "        else:\n",
    "            return torch.FloatTensor(img_transformed ), int(label)\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "773b9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "class Task2_Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False, transform=None):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img_path = f\"{self.root}/{filename}\"\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        if self.return_filename: # Normalization\n",
    "            return torch.FloatTensor(img_transformed ), filename\n",
    "        else:\n",
    "            label = np.array([ord(s)-87 if s.isalpha() else int(s) for s in list(label)])\n",
    "            return torch.FloatTensor(img_transformed ), label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81041f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "class Task3_Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False, transform=None):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img_path = f\"{self.root}/{filename}\"\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        if self.return_filename: # Normalization\n",
    "            return torch.FloatTensor(img_transformed ), filename\n",
    "        else:\n",
    "            label = np.array([ord(s)-87 if s.isalpha() else int(s) for s in list(label)])\n",
    "            return torch.FloatTensor(img_transformed ), label\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c872bf98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.052439Z",
     "iopub.status.busy": "2022-11-25T04:50:33.051285Z",
     "iopub.status.idle": "2022-11-25T04:50:33.078651Z",
     "shell.execute_reply": "2022-11-25T04:50:33.077413Z"
    },
    "papermill": {
     "duration": 0.035192,
     "end_time": "2022-11-25T04:50:33.081577",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.046385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train/annotations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_data \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m val_data \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mTRAIN_PATH\u001b[39m}\u001b[39;49;00m\u001b[39m/annotations.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[0;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csv\u001b[39m.\u001b[39mreader(csvfile, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[39mif\u001b[39;00m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m \u001b[39m0.7\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train/annotations.csv'"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if random.random() < 0.7:\n",
    "            train_data.append(row)\n",
    "        else:\n",
    "            val_data.append(row)\n",
    "\n",
    "# task1\n",
    "original_ds_task1 = Task1_Dataset(train_data, root=TRAIN_PATH, transform=train_transforms)\n",
    "AutoAugment_ds_task1 = Task1_Dataset(train_data, root=TRAIN_PATH, transform=AutoAugment_transforms)\n",
    "jitter_ds_task1 = Task1_Dataset(train_data, root=TRAIN_PATH, transform=ColorJitter_transforms)\n",
    "angle_ds_task1 = Task1_Dataset(train_data, root=TRAIN_PATH, transform=RandomPerspective_transforms)\n",
    "train_ds_task1 = ConcatDataset([original_ds_task1, AutoAugment_ds_task1, jitter_ds_task1, angle_ds_task1])\n",
    "train_dl_task1 = DataLoader(train_ds_task1, batch_size=500, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds_task1 = Task1_Dataset(val_data, root=TRAIN_PATH, transform=val_transforms)\n",
    "val_dl_task1 = DataLoader(val_ds_task1, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "# task2\n",
    "original_ds_task2 = Task2_Dataset(train_data, root=TRAIN_PATH, transform=train_transforms)\n",
    "AutoAugment_ds_task2 = Task2_Dataset(train_data, root=TRAIN_PATH, transform=AutoAugment_transforms)\n",
    "jitter_ds_task2 = Task2_Dataset(train_data, root=TRAIN_PATH, transform=ColorJitter_transforms)\n",
    "angle_ds_task2 = Task2_Dataset(train_data, root=TRAIN_PATH, transform=RandomPerspective_transforms)\n",
    "train_ds_task2 = ConcatDataset([original_ds_task2, AutoAugment_ds_task2, jitter_ds_task2, angle_ds_task2])\n",
    "train_dl_task2 = DataLoader(train_ds_task2, batch_size=500, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds_task2 = Task2_Dataset(val_data, root=TRAIN_PATH, transform=val_transforms)\n",
    "val_dl_task2 = DataLoader(val_ds_task2, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "# task3\n",
    "original_ds_task3 = Task3_Dataset(train_data, root=TRAIN_PATH, transform=train_transforms)\n",
    "AutoAugment_ds_task3 = Task3_Dataset(train_data, root=TRAIN_PATH, transform=AutoAugment_transforms)\n",
    "jitter_ds_task3 = Task3_Dataset(train_data, root=TRAIN_PATH, transform=ColorJitter_transforms)\n",
    "angle_ds_task3 = Task3_Dataset(train_data, root=TRAIN_PATH, transform=RandomPerspective_transforms)\n",
    "train_ds_task3 = ConcatDataset([original_ds_task3, AutoAugment_ds_task3, jitter_ds_task3, angle_ds_task3])\n",
    "train_dl_task3 = DataLoader(train_ds_task3, batch_size=32, num_workers=0, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds_task3 = Task3_Dataset(val_data, root=TRAIN_PATH, transform=val_transforms)\n",
    "val_dl_task3 = DataLoader(val_ds_task3, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "# print(train_ds.__getitem__(0))\n",
    "# cv2.imshow(\"h\", train_ds.__getitem__(0)[0].numpy())\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738e1071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:50:33.090477Z",
     "iopub.status.busy": "2022-11-25T04:50:33.090030Z",
     "iopub.status.idle": "2022-11-25T04:54:08.645651Z",
     "shell.execute_reply": "2022-11-25T04:54:08.643963Z"
    },
    "papermill": {
     "duration": 215.563244,
     "end_time": "2022-11-25T04:54:08.648449",
     "exception": false,
     "start_time": "2022-11-25T04:50:33.085205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(num_task=2, num_epoch=1000, learning_rate=0.01, continue_train=False, model_path=None):\n",
    "\n",
    "    print(f\"task {num_task}\")\n",
    "\n",
    "    if num_task == 1:\n",
    "        num_output = 1\n",
    "        num_class = 10\n",
    "        train_dl = train_dl_task1\n",
    "        val_dl = val_dl_task1\n",
    "\n",
    "    elif num_task == 2:\n",
    "        num_output = 2\n",
    "        num_class = 36\n",
    "        train_dl = train_dl_task2\n",
    "        val_dl = val_dl_task2\n",
    "\n",
    "    elif num_task == 3:\n",
    "        num_output = 4\n",
    "        num_class = 36\n",
    "        train_dl = train_dl_task3\n",
    "        val_dl = val_dl_task3\n",
    "        \n",
    "    else:\n",
    "        print(\"task error\")\n",
    "        return\n",
    "    print(\"Start loading pretrain ResNet model\")\n",
    "    \n",
    "    # model.fc = nn.Linear(512, num_output*num_class)\n",
    "    if continue_train:\n",
    "        model = resnet50(ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(2048, 2*num_class)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.Linear(1024, num_output*num_class)\n",
    "        )\n",
    "    else:\n",
    "        model = resnet50(ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(2048, num_output*num_class)\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(\"Successfully load pretrain ResNet model\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss() #.cuda(args.gpu)\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.1,\n",
    "    #                             momentum=0.9,\n",
    "    #                             weight_decay=1e-4)\n",
    "\n",
    "    # model = DenseNet(48, (12, 24, 48, 36), 96, num_classes=num_class * num_output).to(device)  # 161\n",
    "    # model = torch.load(\"pretrained model\\TPS-ResNet-BiLSTM-Attn.pth\")\n",
    "    # model = densenet161(num_classes=num_class * num_output).to(device)\n",
    "\n",
    "    for epoch in range( num_epoch):\n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"Epoch [{epoch}]\")\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for image, label in train_dl:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).to(torch.int64)\n",
    "\n",
    "            # label = label.unsqueeze(1)\n",
    "            # label = label.expand(-1, 4)\n",
    "\n",
    "            y_pred = model(image)\n",
    "            if num_task == 1:\n",
    "                loss = criterion(y_pred, label)#.type(torch.LongTensor))\n",
    "            else:\n",
    "                y_pred = torch.unflatten(y_pred, dim=1, sizes=(num_output, num_class))\n",
    "                loss = sum(criterion(y_pred[:,i], label[:,i]) for i in range(num_output))\n",
    "            train_loss += loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        sample_count = 0\n",
    "        correct_count = 0\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        for image, label in val_dl:\n",
    "            image = image.to(device)\n",
    "            label = label.to(device).to(torch.int64)\n",
    "\n",
    "\n",
    "            # label = label.unsqueeze(1)\n",
    "            # label = label.expand(-1, 4)\n",
    "            y_pred = model(image)\n",
    "            \n",
    "            if num_task == 1:\n",
    "                loss = criterion(y_pred, label)\n",
    "            else:\n",
    "                y_pred = torch.unflatten(y_pred, dim=1, sizes=(num_output, num_class))\n",
    "                loss = sum(criterion(y_pred[:,i], label[:,i]) for i in range(num_output))\n",
    "\n",
    "            val_loss += loss\n",
    "            sample_count += len(image)\n",
    "\n",
    "            if num_task == 1:\n",
    "                y_pred = torch.argmax(y_pred, dim=1)\n",
    "                correct_count += (label == y_pred).sum()\n",
    "\n",
    "            else:\n",
    "                y_pred = torch.argmax(y_pred, dim=2)\n",
    "                correct_count += (torch.all(label == y_pred, 1)).sum()\n",
    "        \n",
    "        train_loss = train_loss.detach().cpu().numpy()\n",
    "        val_loss = val_loss.detach().cpu().numpy()\n",
    "        val_acc = (correct_count / sample_count).cpu().numpy()\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            torch.save(model.state_dict(), f\"saved_model/task{num_task}/normalized_ResNet50_lr_{learning_rate}/epoch{epoch}_val_acc_{val_acc:.3f}_train_loss_{train_loss:.3f}_val_loss_{val_loss:.3f}.pth\")\n",
    "            print(\"val acc = \", val_acc, \"train loss = \", train_loss, \" val loss = \", val_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scene text recognition dataset's pretrained model\n",
    "# # lr_lst = [ 5e-3, 1e-3, 5e-4]\n",
    "# lr_lst = [ 8e-3]\n",
    "# for lr in lr_lst:\n",
    "#     model = train(num_task=2, num_epoch=2000, learning_rate=lr, continue_train=False, model_path=\"saved_model/task2/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3f2d75b",
   "metadata": {},
   "source": [
    "# Start inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = []\n",
    "with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        test_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fe627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataloader for task1,2,3\n",
    "# task 1 : not normalized\n",
    "# task 2 : normalized\n",
    "# task 3 : normalized\n",
    "test_ds_1 = Task1_Dataset(test_data, root=TEST_PATH, return_filename=True, transform=test_transforms_unnormalized)\n",
    "test_dl_1 = DataLoader(test_ds_1, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n",
    "test_ds_2 = Task2_Dataset(test_data, root=TEST_PATH, return_filename=True, transform=test_transforms)\n",
    "test_dl_2 = DataLoader(test_ds_2, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n",
    "test_ds_3 = Task3_Dataset(test_data, root=TEST_PATH, return_filename=True, transform=test_transforms)\n",
    "test_dl_3 = DataLoader(test_ds_3, batch_size=500, num_workers=0, drop_last=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832ec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load task1 model\n",
    "model1 = resnet152()\n",
    "model1.load_state_dict(torch.load(\"best_model_task1.pth\"))\n",
    "# load task2 model\n",
    "model2 = resnet50()\n",
    "model2.fc = nn.Linear(2048, 2*36)\n",
    "model2.load_state_dict(torch.load(\"best_model_normalized_task2.pth\"))\n",
    "# load task3 model\n",
    "model3 = resnet50()\n",
    "model3.fc = nn.Linear(2048, 4*36)\n",
    "model3.load_state_dict(torch.load(\"best_model_normalized_task3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cdd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-25T04:54:08.670764Z",
     "iopub.status.busy": "2022-11-25T04:54:08.670326Z",
     "iopub.status.idle": "2022-11-25T04:54:15.658960Z",
     "shell.execute_reply": "2022-11-25T04:54:15.657332Z"
    },
    "papermill": {
     "duration": 7.003498,
     "end_time": "2022-11-25T04:54:15.662139",
     "exception": false,
     "start_time": "2022-11-25T04:54:08.658641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_task =  1\n",
      "num_task =  2\n",
      "num_task =  3\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# open submission.csv\n",
    "num_tasks = [1, 2, 3]\n",
    "total_len = 0\n",
    "        \n",
    "write_lst = []\n",
    "for num_task in num_tasks:\n",
    "    print(\"num_task = \", num_task)\n",
    "\n",
    "    # Load model\n",
    "    if num_task == 1:\n",
    "         model = model1.to(device)\n",
    "         test_dl = test_dl_1\n",
    "    elif num_task == 2:\n",
    "        model = model2.to(device)\n",
    "        test_dl = test_dl_2\n",
    "    else:\n",
    "        model = model3.to(device)\n",
    "        test_dl = test_dl_3\n",
    "    # Write prediction per batch\n",
    "    model.eval()\n",
    "    for image, filenames in test_dl:\n",
    "        image = image.to(device)\n",
    "    \n",
    "        y_pred = model(image)\n",
    "        if num_task == 1:\n",
    "            y_pred = torch.argmax(y_pred, dim=1)\n",
    "            output = y_pred\n",
    "        elif num_task == 2:\n",
    "            y_pred = torch.unflatten(y_pred, dim=1, sizes=(2, 36))\n",
    "            output = torch.argmax(y_pred, dim=2)\n",
    "        elif num_task == 3:\n",
    "            y_pred = torch.unflatten(y_pred, dim=1, sizes=(4, 36))\n",
    "            output = torch.argmax(y_pred, dim=2)\n",
    "\n",
    "        if len(filenames) != 500:\n",
    "            print(\"len(filenames) = \", len(filenames))\n",
    "        total_len += len(filenames)\n",
    "        \n",
    "        # Start writing csv\n",
    "        for i in range(len(filenames)):\n",
    "            try:\n",
    "                write_lst.append((filenames[i], str(output[i].item())))\n",
    "                # tmp = type(output[i].item())\n",
    "                # csv_writer.writerow([filenames[i], str(output[i].item())])\n",
    "            except:\n",
    "                batch_output = \"\"\n",
    "                for class_num in output[i]:\n",
    "                    if class_num < 10:\n",
    "                        batch_output += str(class_num.item())\n",
    "                    else:\n",
    "                        batch_output += chr(class_num+87)\n",
    "                \n",
    "                write_lst.append((filenames[i], batch_output))\n",
    "                # csv_writer.writerow([filenames[i], batch_output])\n",
    "\n",
    "    # # Open csv file\n",
    "    # if os.path.exists('submission.csv'):\n",
    "    #     csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
    "    # else:\n",
    "    #     csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "    #     csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "    for filename, prediction in write_lst:\n",
    "        csv_writer.writerow([filename, prediction])\n",
    "\n",
    "print(total_len)\n",
    "    # for filename, _ in test_data:\n",
    "    #     if filename.startswith(\"task2\") or filename.startswith(\"task3\"):\n",
    "    #         csv_writer.writerow([filename, 0])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eda69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842fec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 242.076508,
   "end_time": "2022-11-25T04:54:16.697471",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-25T04:50:14.620963",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "29931e1b5fd008239d71c860573e1ff80df036f9c7b6fafc66d2e0549fca9a87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
